{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"],temperature=0.5, max_tokens=100)\n",
    "response = llm.predict(\"translate English to gujrati: Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "hub = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",  # The Hugging Face model you want to use\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    "    model_kwargs = {\"temperature\": 0.9, \"max_length\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = hub.predict(\n",
    "    \"Give me the names of 5 Hindu lords, numbered in this format:\\n1.\\n2.\\n3.\\n4.\\n5.\"\n",
    ")\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=hub.predict(\"write a poem about AI\")\n",
    "print(output)\n",
    "response=llm.predict(\"write a poem about AI\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt=PromptTemplate(\n",
    "\n",
    "input_variables=[\"country\"],\n",
    "template=\"capital of the {country}\"\n",
    "\n",
    ")\n",
    "\n",
    "pro=prompt.format(country=\"india\")\n",
    "\n",
    "print(pro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1 way\n",
    "response=llm.predict(pro)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2 way\n",
    "from langchain import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt)\n",
    "\n",
    "response=chain.predict(country=\"usa\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple sequential chain\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    \n",
    "    input_variables={\"country\"},\n",
    "    template=\"what is the capital of the {country}?\")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    input_variables={\"capital\"},\n",
    "    template=\"what are the 4 traveling spots in {capital} ?\")\n",
    "\n",
    "chain1=LLMChain(llm=llm,prompt=prompt1)\n",
    "chain2=LLMChain(llm=llm,prompt=prompt2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[chain1,chain2])\n",
    "result=chain.run({\"India\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential chains\n",
    "\n",
    "simple sequential and sequential searrch ma thodo farak hoy 6e \n",
    "je main diffrence 6e ae 6e simple ae simple 6e,aetle aema apde kai chain 1 no out chain 2\n",
    "ma nakhvani jaroor nathi, ae automatic 6e\n",
    "\n",
    "jyare sequential ma apde jate manually karvu pade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3=PromptTemplate(\n",
    "\n",
    "    input_variables={\"country\"},\n",
    "    template=(\"what is the capital of the {country}?\")\n",
    ")\n",
    "\n",
    "prompt4=PromptTemplate(\n",
    "    input_variables={\"capital\"},\n",
    "    template=\"what are the 4 traveling spots in {capital} ?\"\n",
    ")\n",
    "\n",
    "chain3=LLMChain(llm=llm,prompt=prompt3,output_key=\"capital\")\n",
    "rchain3=chain3.predict(country=\"India\")\n",
    "chain4=LLMChain(llm=llm,prompt=prompt4,output_key=\"spots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "schain=SequentialChain(\n",
    "    chains=[chain3,chain4],\n",
    "    input_variables=[\"country\"],\n",
    "    output_variables=[\"capital\",\"spots\"] )           \n",
    "                      \n",
    "\n",
    "result=schain({\"country\":\"India\"})\n",
    "final_output=f\" {result['capital']} and the 4 traveling spots are {result['spots']}\"\n",
    "print(final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chatmodels with chatopenai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"openai_api_key\"],temperature=0.6,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[\n",
    "\n",
    "SystemMessage(content=\"you are comedian ai\" ),\n",
    "HumanMessage(content=\"tell me a  joke about donald trupm and joe biden\"),\n",
    "\n",
    "]\n",
    "response=chatllm(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatprompt template + LLM + output parsers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoparser(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"you are my helpful assisant, always help, me , alot, you genarate synonyms of the word \"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|demoparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyful',\n",
       " ' delighted',\n",
       " ' content',\n",
       " ' pleased',\n",
       " ' ecstatic',\n",
       " ' cheerful',\n",
       " ' blissful',\n",
       " ' jubilant',\n",
       " ' elated',\n",
       " ' euphoric']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"happy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
